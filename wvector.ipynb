{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c3ae6a",
   "metadata": {},
   "source": [
    "# Compute Wasserstein vector between two ensembles\n",
    "## Difference between the empirical local structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151c5dcd",
   "metadata": {},
   "source": [
    "Important note: Python version needs to be set to __Python 3.8__ to be able to load the library `faiss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b9ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from functools import partial\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f17712",
   "metadata": {},
   "source": [
    "The function `wasserstein_i` computes __Wasserstein distance__ between the i-th dihedral angles distributions (the i-th element of the __empirical local structures__) of a pair of (replicas of two) ensembles. This function will be parallelized across all sequence positions. Its arguments are:\n",
    "\n",
    "* `which_pos`: an integer (i) specifying the i-th sequence position.\n",
    "\n",
    "* `prot_name_1`: the name of the first ensemble, whose .hdf5 dihedrals file is `prot_name_1_dihedrals.hdf5`.\n",
    "\n",
    "* `prot_name_2`: the name of the second ensemble, whose .hdf5 dihedrals file is `prot_name_2_dihedrals.hdf5`.\n",
    "\n",
    "* `ncenters`: the number of clusters when kmeans clustering needs to be performed.\n",
    "\n",
    "* `coor_path`: the path where all the dihedrals .hdf5 files are located.\n",
    "\n",
    "Normally, the user can load `wasserstein_i` and skip to the next function `w_vector`, which integrates `wasserstein_i` and its arguments, and should be used if the complete vector for all sequence positions need to be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d53e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_i(which_pos, prot_name_1, prot_name_2, ncenters, coor_path):\n",
    "    \n",
    "    # Required libraries (need to be placed here for parallel computing)\n",
    "    \n",
    "    import os\n",
    "    import ot\n",
    "    import h5py\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import  # Needs Python 3.8\n",
    "    from scipy.spatial.distance import cdist\n",
    "    \n",
    "    # Required functions (need to placed here for parallel computing)\n",
    "    \n",
    "    def clustering_torus(prot_elements,n_centers): # Performs kmeans for a sample on the two-dimensional flat torus\n",
    "        \n",
    "        # The clustering is performed by parameterizing (phi, psi) angles as the elements\n",
    "        # (cos(phi), sin(phi), cos(psi), sin(psi)) of R^4. This is known as extrinsic kmeans.\n",
    "        \n",
    "        prot_elements = np.concatenate([np.cos(prot_elements[:,0])[:,None],\n",
    "                                        np.sin(prot_elements[:,0][:,None]),\n",
    "                                        np.cos(prot_elements[:,1][:,None]),\n",
    "                                        np.sin(prot_elements[:,1][:,None])], axis = 1) # Parameterize (phi,psi) values\n",
    "        \n",
    "        kmeans = faiss.Kmeans(d=4, k = ncenters, min_points_per_centroid = 1, max_points_per_centroid = 10000000)\n",
    "        kmeans.train(prot_elements.astype(np.float32))\n",
    "        a = np.concatenate([np.arctan2(kmeans.centroids[:,1],kmeans.centroids[:,0])[:,None],\n",
    "                            np.arctan2(kmeans.centroids[:,3],kmeans.centroids[:,2])[:,None]],axis=1) # Back to (phi,psi) after clustering\n",
    "       \n",
    "            \n",
    "        kmeans_labels = kmeans.index.search(prot_elements.astype(np.float32),1)[1] # Support of the \"clustered distribution\"\n",
    "        empty_clusters = np.setdiff1d(np.arange(n_centers), kmeans_labels) # Check for empty clusters\n",
    "        mass = pd.DataFrame(kmeans_labels).value_counts().sort_index()\n",
    "        mass_norm = np.array(mass/np.sum(mass)) # Probability mass assigned to each cluster\n",
    "        \n",
    "        if len(empty_clusters) > 0: # Remove empty clusters\n",
    "            a = np.delete(a, empty_clusters, axis = 0)\n",
    "      \n",
    "        return a, mass_norm\n",
    "    \n",
    "    def metric2_torus(x,y): # Geodesic distance on the two-dimensional flat torus\n",
    "        \n",
    "        return sum(np.minimum(np.abs(x-y),1-np.abs(x-y))**2)\n",
    "    \n",
    "    ###########################################################################\n",
    "   \n",
    "    # Extract i-th (phi, psi) distributions for both ensembles\n",
    "    os.chdir(coor_path)\n",
    "    \n",
    "    h5f_1 = h5py.File(\"_\".join([prot_name_1,'dihedrals.hdf5']),'r')\n",
    "    L1 = int(0.5*(1 + np.sqrt(1 + 8*np.shape(h5f_1['ensemble'])[1])))\n",
    "    pos_ij_prot_1 = h5f_1['ensemble'][:, which_pos , :] # Access only to angles of i-th residue\n",
    "    h5f_1.close()\n",
    "     \n",
    "    h5f_2 = h5py.File(\"_\".join([prot_name_2,'dihedrals.hdf5']),'r')\n",
    "    L2 = int(0.5*(1 + np.sqrt(1 + 8*np.shape(h5f_2['ensemble'])[1])))\n",
    "    pos_ij_prot_2 = h5f_2['ensemble'][:, which_pos , :] # Access only to angles of i-th residue\n",
    "    h5f_2.close()\n",
    "    \n",
    "    pos_ij_prot_1 = pos_ij_prot_1[~np.isnan(pos_ij_prot_1).any(axis=1),:] # Remove missing conformations\n",
    "    pos_ij_prot_2 = pos_ij_prot_2[~np.isnan(pos_ij_prot_2).any(axis=1),:] \n",
    "       \n",
    "    if L1 != L2: \n",
    "        quit('Both ensembles must have the same length') \n",
    "    \n",
    "    n = np.shape(pos_ij_prot_1)[0] # Number of conformations of the first ensemble\n",
    "    m = np.shape(pos_ij_prot_2)[0] # Number of conformations of the second ensemble\n",
    "           \n",
    "    if n <= ncenters: # If clustering is not needed for the first ensemble\n",
    "        \n",
    "        a = pos_ij_prot_1[:,2:4]\n",
    "        ma = np.ones(n)/n\n",
    "            \n",
    "    else: # Clustering for the first ensemble\n",
    "                        \n",
    "        a, ma = clustering_torus(pos_ij_prot_1[:,2:4], ncenters) \n",
    "    \n",
    "    if m <= ncenters: # If clustering is not needed for the second ensemble\n",
    "                        \n",
    "        b = pos_ij_prot_2[:,2:4]\n",
    "        mb = np.ones(m)/m\n",
    "            \n",
    "    else: # Clustering for the second ensemble\n",
    "                      \n",
    "        b, mb = clustering_torus(pos_ij_prot_2[:,2:4], ncenters)\n",
    "       \n",
    "    M = cdist(a, b, metric2_torus) # Cost matrix\n",
    "    clean = ot.utils.clean_zeros(ma, mb, M)\n",
    "    w_i = np.sqrt(ot.emd2(clean[0], clean[1], clean[2])) # 2-Wasserstein distance    \n",
    "   \n",
    "    return w_i, n, m # Returning Wasserstein distance together with sample sizes (needed to compute p-values)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312691d5",
   "metadata": {},
   "source": [
    "The function `w_vector` parallelizes `wasserstein_i` across the list of all sequence positions. Therefore, it computes the Wasserstein vector representing the difference between the empirical local structures of a pair of (replicas of two) ensembles. The function returns an array of shape [number of sequence positions, 5] array, ready to be graphically represented (using function `plot_matrix`). For a given sequence position i, (i = 1,...,L), the array's element [i-1,:] contains the vector `[i, w_i, n, m, AA_i]`, where `w_i` is the Wasserstein distance between both ensemble's i-th dihedrals distributions, `n`, `m` the number of conformations of the first and second ensemble respectively, and `AA_i` the identity of the i-th residue (given as its index in the alphabetically ordered amino acid list).\n",
    "\n",
    "The arguments of `w_vector` are:\n",
    "\n",
    "* `prot_name_1`: the name of the first ensemble, whose .hdf5 dihedrals file is `prot_name_1_dihedrals.hdf5`.\n",
    "\n",
    "* `prot_name_2`: the name of the second ensemble, whose .hdf5 dihedrals file is `prot_name_2_dihedrals.hdf5`.\n",
    "\n",
    "* `N_centers`: the number of clusters when kmeans clustering needs to be performed.\n",
    "\n",
    "* `data_path`: the path where all the dihedrals .hdf5 files are located.\n",
    "\n",
    "The computation time may be long, depending on both ensemble sizes (sequence length, number of conformations).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863f0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_vector(prot_1, prot_2, N_centers, N_cores, data_path):\n",
    "  \n",
    "    os.chdir(data_path) # Some data needs to be loaded to extract needed parameters\n",
    "    h5f_1 = h5py.File(\"_\".join([prot_1,'dihedrals.hdf5']),'r')\n",
    "    L1 = np.shape(h5f_1['ensemble'])[1] # Sequence length\n",
    "    it_pos = range(1,L1-1) # List of sequence positions\n",
    "    res_list = h5f_1['ensemble'][0,1:(L1-1),0][:,None] # List of residues identities along the sequence\n",
    "    del(h5f_1) # Free memory\n",
    "    \n",
    "    it_function = partial(wasserstein_i, prot_name_1 = prot_1, prot_name_2 = prot_2,\n",
    "                         ncenters = N_centers, coor_path = data_path) \n",
    "    \n",
    "    print('-------------------------------------------------------------------\\n')\n",
    "    print(\"\".join(['Computing Wasserstein distances for ', str(len(res_list)), ' sequence positions.\\n']))\n",
    "    print(\"\".join(['Protein 1 : ', prot_1,'\\n']))\n",
    "    print(\"\".join(['Protein 2 : ', prot_2,'\\n']))\n",
    "    print('-------------------------------------------------------------------\\n')   \n",
    "\n",
    "    \n",
    "    if __name__ == \"__main__\": # Parallel computing\n",
    "        w_distances = Parallel(n_jobs = N_cores, verbose=10, backend = 'threading')(delayed(it_function)(i) for i in it_pos)\n",
    "    \n",
    "    positions = np.asarray(it_pos)[:,None]\n",
    "    distances = np.reshape(np.asarray(w_distances), [np.shape(w_distances)[0], 3])\n",
    "    \n",
    "    return np.concatenate([positions, distances, res_list], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7244f4",
   "metadata": {},
   "source": [
    "## Executing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5141b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_name_1 = \"my_ensemble_1\"\n",
    "prot_name_2 = \"my_ensemble_2\"\n",
    "coordinates_path = \"/path_to_coordinates_folder\" # Folder where my_ensemble_1_dihedrals.hdf5 and my_ensemble_2_dihedrals.hdf5 are located\n",
    "\n",
    "n_clusters = 2000 # Recommended number of clusters\n",
    "n_cores = 1 # Number of cores for parallel computing\n",
    "\n",
    "wvector = w_vector(prot_1 = prot_name_1, prot_2 = prot_name_2 , N_centers = n_clusters, N_cores = n_cores, data_path = coordinates_path)\n",
    "\n",
    "# The resulting vector should be saved (needed for graphic representation)\n",
    "os.chdir('save_in_this_path')\n",
    "np.save(\"_\".join([prot_name_1,prot_name_2,'wvector.npy']), wmatrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
